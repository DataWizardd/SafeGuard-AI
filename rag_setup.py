import os
import shutil
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
# [ë³€ê²½] OpenAI ëŒ€ì‹  HuggingFaceEmbeddings ì‚¬ìš©
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

DB_PATH = "./faiss_db"

def get_retriever():
    """
    ì €ì¥ëœ FAISS DBê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ BGE-M3 ëª¨ë¸ë¡œ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.
    """
    
    # [ë³€ê²½ 1] ì„ë² ë”© ëª¨ë¸ì„ 'BAAI/bge-m3'ë¡œ êµì²´
    # bge-m3ëŠ” ë‹¤êµ­ì–´(í•œêµ­ì–´ í¬í•¨) ì„±ëŠ¥ì´ ë§¤ìš° ë›°ì–´ë‚œ SOTA ëª¨ë¸ì…ë‹ˆë‹¤.
    print("ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘ (BAAI/bge-m3)...")
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-m3",
        model_kwargs={'device': 'cpu'}, # GPUê°€ ìˆë‹¤ë©´ 'cuda'ë¡œ ë³€ê²½
        encode_kwargs={'normalize_embeddings': True} # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ìœ„í•´ ì •ê·œí™”
    )

    # 1. ì´ë¯¸ ë§Œë“¤ì–´ì§„ DBê°€ ìˆëŠ”ì§€ í™•ì¸
    if os.path.exists(DB_PATH):
        print("ğŸ’¾ ê¸°ì¡´ ë²¡í„° DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
        try:
            vectorstore = FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)
            
            # [ë³€ê²½ 2] ê³ ê¸‰ ê²€ìƒ‰ ì„¤ì •: ìœ ì‚¬ë„ 0.7 ì´ìƒì¸ ê²ƒë§Œ ìµœëŒ€ 8ê°œ ê°€ì ¸ì˜¤ê¸°
            return vectorstore.as_retriever(
                search_type="similarity", # threshold ë°©ì‹ ëŒ€ì‹  ê¸°ë³¸ similarity ì¶”ì²œ
                search_kwargs={"k": 6}    # ê°œìˆ˜ëŠ” 6ê°œ ì •ë„
            )
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ DB ë¡œë“œ ì‹¤íŒ¨ (ì•„ë§ˆë„ ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜): {e}")
            print("ğŸ—‘ï¸ ê¸°ì¡´ DBë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            shutil.rmtree(DB_PATH) # í´ë” ì‚­ì œ

    # 2. ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (PDF ë¡œë“œ)
    print("ğŸ”„ ìƒˆë¡œìš´ ë²¡í„° DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    if not os.path.exists("./data"):
        os.makedirs("./data")
        print("âš ï¸ 'data' í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return None

    documents = []
    for file in os.listdir("./data"):
        if file.endswith(".pdf"):
            print(f"   - ë¡œë”© ì¤‘: {file}")
            loader = PyPDFLoader(f"./data/{file}")
            docs = loader.load()
            documents.extend(docs)

    if not documents:
        print("âŒ ë¡œë“œí•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # 3. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
    # BGE-M3ëŠ” ê¸´ ë¬¸ë§¥ë„ ì˜ ì²˜ë¦¬í•˜ë¯€ë¡œ chunk_sizeë¥¼ ì¡°ê¸ˆ ë„‰ë„‰í•˜ê²Œ ì¤˜ë„ ë©ë‹ˆë‹¤.
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    splits = text_splitter.split_documents(documents)

    # 4. ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ì €ì¥
    print("vectors ìƒì„± ì¤‘... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    vectorstore = FAISS.from_documents(splits, embeddings)
    vectorstore.save_local(DB_PATH)
    print("ğŸ‰ DB ìƒì„± ë° ì €ì¥ ì™„ë£Œ!")

    # ë¦¬í„´ ì‹œì—ë„ ë™ì¼í•œ ê²€ìƒ‰ ì¡°ê±´ ì ìš©
    return vectorstore.as_retriever(
        search_type="similarity_score_threshold",
        search_kwargs={
            "score_threshold": 0.4, 
            "k": 8
        }
    )

if __name__ == "__main__":
    get_retriever()